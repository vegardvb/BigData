# Big Data Architecture Projects

## Overview
This repository contains three projects for the **TDT4305 - Big Data Architecture** course, covering large-scale data processing, text similarity detection, and data stream mining. Each project is structured to explore different aspects of big data processing using Apache Spark, MinHash, Locality Sensitive Hashing (LSH), DGIM, Bloom Filters, AdWords optimization, and Recommendation Systems.

## Repository Structure
```
/
    |-- project1/  (Introduction to Apache Spark)
    |-- project2/  (Finding Similar News Articles)
    |-- project3/  (Mining Data Streams, AdWords, and Recommendation Systems)
    |-- README.md  (This file)
```

## Project Descriptions

### Project 1: Introduction to Apache Spark
- Focuses on large-scale data processing using Apache Spark.
- Includes schema definition, SQL queries, correlation analysis, and machine learning with Spark MLib.
- **Path:** `/project1/`

### Project 2: Finding Similar News Articles
- Implements MinHash and Locality Sensitive Hashing (LSH) to detect similar articles.
- Works with BBC News dataset for efficient document similarity detection.
- **Path:** `/project2/`

### Project 3: Mining Data Streams, AdWords, and Recommendation Systems
- Covers real-time data processing techniques.
- Implements DGIM, Bloom Filters, AdWords revenue optimization, and recommendation systems.
- **Path:** `/project3/`

## Setup Instructions

### General Requirements
- Ensure **Python 3.8+** is installed.
- Install dependencies:
  ```bash
  pip install numpy pandas
  ```

### Project-Specific Instructions
Each project has its own `README.md` file with setup instructions and execution steps. Navigate to the respective project folder and follow the guidelines.

## Submission Guidelines
- Ensure all required files are included in each project's `.zip` submission.
- Each submission must include Jupyter Notebooks or Python scripts as specified.
- Follow the naming conventions mentioned in each project README.

## References
- [Apache Spark](https://spark.apache.org/docs/latest/)
- [MinHash & LSH](https://en.wikipedia.org/wiki/Locality-sensitive_hashing)
- [DGIM Algorithm](https://en.wikipedia.org/wiki/Datar-Gionis-Indyk-Motwani_algorithm)
- [Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering)

For any questions, refer to the project-specific README files. **Good luck!** ðŸš€