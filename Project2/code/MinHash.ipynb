{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe94871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hashlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4f5bf9",
   "metadata": {},
   "source": [
    "Name A: Vegard Vaeng Bernhardsen\n",
    "\n",
    "Name B: None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d4a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Four (4) 'relevant' TDT4305 sentences\n",
    "\n",
    "Sentence_1 = \"The Big Data platform for students is Blackboard\"\n",
    "Sentence_2 = \"Questions on MinHash project by NTNU students is on Piazza\"\n",
    "Sentence_3 = \"NTNU Big Data platform are Blackboard and Piazza\"\n",
    "Sentence_4 = \"The project data for students are on Blackboard not Piazza\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f619be36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['big', 'blackboard', 'data', 'minhash', 'ntnu', 'piazza', 'platform', 'project', 'questions', 'students']\n"
     ]
    }
   ],
   "source": [
    "words = [\"big\", \"blackboard\", \"data\", \"platform\", \"students\", \"questions\", \"minhash\", \"project\", \"ntnu\", \"piazza\"]\n",
    "\n",
    "# Organize the array in alphabetical order\n",
    "sorted_words = sorted(words)\n",
    "\n",
    "print(sorted_words)\n",
    "\n",
    "unique_words = sorted_words # Enter the unique words list here\n",
    "\n",
    "# ['big', 'blackboard', 'data', 'minhash', 'ntnu', 'piazza', 'platform', 'project', 'questions', 'students']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e633fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format: ['word', 'word', 'word' ...] & watch out for white spaces before comma\n",
      "Correct! Your dictionary matched!\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "\n",
    "print(f\"Format: ['word', 'word', 'word' ...] & watch out for white spaces before comma\")\n",
    "user_input = str(sorted_words) # str(input(\"Enter your created list of unique words: \")) \n",
    "# Changed to str(sorted_words) for testing purposes\n",
    "\n",
    "f = open(\"encrypted_dictionary.txt\", \"r\")\n",
    "encrypted_words = f.read()\n",
    "\n",
    "\n",
    "# Hash the user input\n",
    "hashed_user_input = hashlib.sha256(user_input.encode()).hexdigest()\n",
    "\n",
    "# Compare with the stored hash\n",
    "if hashed_user_input == encrypted_words:\n",
    "    print(\"Correct! Your dictionary matched!\")\n",
    "else:\n",
    "    print(\"Incorrect! Try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b10d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix:\n",
      "[[1 0 1 0]\n",
      " [1 0 1 1]\n",
      " [1 0 1 1]\n",
      " [0 1 0 0]\n",
      " [0 1 1 0]\n",
      " [0 1 1 1]\n",
      " [1 0 1 0]\n",
      " [0 1 0 1]\n",
      " [0 1 0 0]\n",
      " [1 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Lowercase sentences for uniform processing\n",
    "sentences = [Sentence_1.lower(), Sentence_2.lower(), Sentence_3.lower(), Sentence_4.lower()]\n",
    "\n",
    "# Initialize the Input Matrix\n",
    "input_matrix = np.zeros((len(unique_words), len(sentences)), dtype=int)\n",
    "\n",
    "# Populate the Input Matrix\n",
    "for i, word in enumerate(unique_words):\n",
    "    for j, sentence in enumerate(sentences):\n",
    "        if word in sentence:\n",
    "            input_matrix[i, j] = 1\n",
    "\n",
    "print(\"Input Matrix:\")\n",
    "print(input_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4873b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_list: [[5, 6, 7, 8, 9, 10, 1, 2, 3, 4], [9, 6, 3, 10, 7, 4, 1, 8, 5, 2], [10, 7, 4, 1, 8, 5, 2, 9, 6, 3]]\n"
     ]
    }
   ],
   "source": [
    "n = len(unique_words)\n",
    "\n",
    "hash_1 = []\n",
    "for i in range(1, n + 1):\n",
    "    hash_1.append( ( ( (i + 3) % 10 ) + 1) )\n",
    "    \n",
    "hash_2 = []\n",
    "for i in range(1, n + 1):\n",
    "    hash_2.append( ( ( (7 * i + 1) % 10 ) + 1) )\n",
    "\n",
    "hash_3 = []\n",
    "for i in range(1, n + 1):\n",
    "    hash_3.append( ( ( (7 * i + 2) % 10 ) + 1) )\n",
    "\n",
    "hash_list = [hash_1, hash_2, hash_3]\n",
    "\n",
    "print(\"hash_list:\", hash_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a78ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinHash Signature Matrix:\n",
      "[[1 2 1 2]\n",
      " [1 2 1 2]\n",
      " [2 1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Signature Matrix with infinite values\n",
    "Sig_M = np.full((3, len(sentences)), np.inf)\n",
    "\n",
    "# Compute the MinHash Signature Matrix\n",
    "for i in range(Sig_M.shape[0]):\n",
    "    for j in range(Sig_M.shape[1]):\n",
    "        for k in range(len(unique_words)):\n",
    "            if input_matrix[k, j] == 1:\n",
    "                Sig_M[i, j] = min(Sig_M[i, j], hash_list[i][k])\n",
    "\n",
    "print(\"MinHash Signature Matrix:\")\n",
    "print(Sig_M.astype(int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad809788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity between Sentence 1 and Sentence 2: 0.000\n",
      "Jaccard Similarity between Sentence 1 and Sentence 3: 1.000\n",
      "Jaccard Similarity between Sentence 1 and Sentence 4: 0.000\n",
      "Jaccard Similarity between Sentence 2 and Sentence 3: 0.000\n",
      "Jaccard Similarity between Sentence 2 and Sentence 4: 0.667\n",
      "Jaccard Similarity between Sentence 3 and Sentence 4: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Jaccard similarity between two columns in the signature matrix\n",
    "def calculate_jaccard(Sig_M, col1, col2):\n",
    "    match = np.sum(Sig_M[:, col1] == Sig_M[:, col2])\n",
    "    return match / Sig_M.shape[0]\n",
    "\n",
    "# Display Jaccard Similarity for each sentence pair\n",
    "for i in range(Sig_M.shape[1]):\n",
    "    for j in range(i + 1, Sig_M.shape[1]):\n",
    "        similarity = calculate_jaccard(Sig_M, i, j)\n",
    "        print(f\"Jaccard Similarity between Sentence {i + 1} and Sentence {j + 1}: {similarity:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
